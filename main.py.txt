import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.multioutput import MultiOutputClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score

# Load the datasets
training_features = pd.read_csv('path_to_training_set_features.csv')
training_labels = pd.read_csv('path_to_training_set_labels.csv')
test_features = pd.read_csv('path_to_test_set_features.csv')
submission_format = pd.read_csv('path_to_submission_format.csv')

# Identify features and target
features = training_features.drop(columns=['respondent_id'])
target = training_labels[['xyz_vaccine', 'seasonal_vaccine']]

# Split data into training and validation sets
X_train, X_valid, y_train, y_valid = train_test_split(features, target, test_size=0.2, random_state=42)

# Preprocessing: Handle categorical and numerical features
categorical_features = [col for col in features.columns if features[col].dtype == 'object']
numerical_features = [col for col in features.columns if features[col].dtype in ['int64', 'float64']]

preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numerical_features),
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
    ])

# Model pipeline
model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', MultiOutputClassifier(RandomForestClassifier(random_state=42)))
])

# Hyperparameter tuning (example with RandomForest)
param_grid = {
    'classifier__estimator__n_estimators': [100, 200],
    'classifier__estimator__max_depth': [None, 10, 20],
    'classifier__estimator__min_samples_split': [2, 5, 10]
}

grid_search = GridSearchCV(model, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)
grid_search.fit(X_train, y_train)

# Best model
best_model = grid_search.best_estimator_

# Make predictions on the validation set
y_pred_proba_valid = best_model.predict_proba(X_valid)

# Calculate ROC AUC score for each target
roc_auc_xyz = roc_auc_score(y_valid['xyz_vaccine'], y_pred_proba_valid[0][:, 1])
roc_auc_seasonal = roc_auc_score(y_valid['seasonal_vaccine'], y_pred_proba_valid[1][:, 1])
mean_roc_auc = (roc_auc_xyz + roc_auc_seasonal) / 2

print(f'Mean ROC AUC score: {mean_roc_auc}')

# Make predictions on the test set
test_features_clean = test_features.drop(columns=['respondent_id'])
test_pred_proba = best_model.predict_proba(test_features_clean)

# Prepare the submission file
submission = pd.DataFrame({
    'respondent_id': test_features['respondent_id'],
    'xyz_vaccine': test_pred_proba[0][:, 1],
    'seasonal_vaccine': test_pred_proba[1][:, 1]
})
submission.to_csv('submission.csv', index=False)
